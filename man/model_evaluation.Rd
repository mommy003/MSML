% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/eval_part2.r
\name{model_evaluation}
\alias{model_evaluation}
\title{model_evaluation function}
\usage{
model_evaluation(dat, mv, tn, prev, pthreshold = 0.05, method = "R2ROC")
}
\arguments{
\item{dat}{This is the matrix for all the combinations of the model}

\item{mv}{The total number of columns in data_train/data_valid}

\item{tn}{The total no of best models to be identified}

\item{prev}{The prevalence of disease in the data}

\item{pthreshold}{The P value threshold for the significance level}

\item{method}{The methods to be used to evaluate models}
}
\value{
This function will generate all possible model outcomes for validation and test dataset
}
\description{
This function will identify the best model in the validation and test dataset.
}
\examples{
\donttest{
dat <- predict_validation
mv=8
tn=15
prev=0.047
out=model_evaluation(dat,mv,tn,prev)
#This process will generate three output files.
#out$out_all, contains AUC, R2, and P-values for all models.
#out$out_start, contains AUC, R2, and P-values for top tn models.
#out$out_selected, contains AUC, R2, and P-values for best models.
#For details (see https://github.com/mommy003/MSML).
}
}
\keyword{Identify}
\keyword{best}
\keyword{models}
